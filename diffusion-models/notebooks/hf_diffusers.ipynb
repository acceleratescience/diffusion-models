{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/usr/local/lib/python3.10/dist-packages/diffusers/models/transformers/transformer_2d.py:34: FutureWarning: `Transformer2DModelOutput` is deprecated and will be removed in version 1.0.0. Importing `Transformer2DModelOutput` from `diffusers.models.transformer_2d` is deprecated and this will be removed in a future version. Please use `from diffusers.models.modeling_outputs import Transformer2DModelOutput`, instead.\n",
      "  deprecate(\"Transformer2DModelOutput\", \"1.0.0\", deprecation_message)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "from diffusers import UNet2DModel\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet2DModel(\n",
    "    sample_size=28,\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    layers_per_block=1,\n",
    "    block_out_channels=(8, 16, 32),\n",
    "    down_block_types=(\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "    ),\n",
    "    up_block_types=(\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "    ),\n",
    "    num_class_embeds=10,\n",
    "    norm_num_groups=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet2DModel(\n",
       "  (conv_in): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (time_proj): Timesteps()\n",
       "  (time_embedding): TimestepEmbedding(\n",
       "    (linear_1): Linear(in_features=8, out_features=32, bias=True)\n",
       "    (act): SiLU()\n",
       "    (linear_2): Linear(in_features=32, out_features=32, bias=True)\n",
       "  )\n",
       "  (class_embedding): Embedding(10, 32)\n",
       "  (down_blocks): ModuleList(\n",
       "    (0): DownBlock2D(\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(1, 8, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=32, out_features=8, bias=True)\n",
       "          (norm2): GroupNorm(1, 8, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "      )\n",
       "      (downsamplers): ModuleList(\n",
       "        (0): Downsample2D(\n",
       "          (conv): Conv2d(8, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): DownBlock2D(\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(1, 8, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=32, out_features=16, bias=True)\n",
       "          (norm2): GroupNorm(1, 16, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (downsamplers): ModuleList(\n",
       "        (0): Downsample2D(\n",
       "          (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): DownBlock2D(\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(1, 16, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (norm2): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_blocks): ModuleList(\n",
       "    (0): UpBlock2D(\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (norm2): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(1, 48, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(48, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (norm2): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (upsamplers): ModuleList(\n",
       "        (0): Upsample2D(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): UpBlock2D(\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(1, 48, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(48, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=32, out_features=16, bias=True)\n",
       "          (norm2): GroupNorm(1, 16, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(48, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(1, 24, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(24, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=32, out_features=16, bias=True)\n",
       "          (norm2): GroupNorm(1, 16, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(24, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (upsamplers): ModuleList(\n",
       "        (0): Upsample2D(\n",
       "          (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): UpBlock2D(\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(1, 24, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(24, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=32, out_features=8, bias=True)\n",
       "          (norm2): GroupNorm(1, 8, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(24, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(1, 16, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=32, out_features=8, bias=True)\n",
       "          (norm2): GroupNorm(1, 8, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mid_block): UNetMidBlock2D(\n",
       "    (attentions): ModuleList(\n",
       "      (0): Attention(\n",
       "        (group_norm): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
       "        (to_q): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (to_k): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (to_v): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (to_out): ModuleList(\n",
       "          (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (1): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (resnets): ModuleList(\n",
       "      (0-1): 2 x ResnetBlock2D(\n",
       "        (norm1): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (time_emb_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (norm2): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (nonlinearity): SiLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_norm_out): GroupNorm(1, 8, eps=1e-05, affine=True)\n",
       "  (conv_act): SiLU()\n",
       "  (conv_out): Conv2d(8, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform to min-max normalize the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x / x.max())\n",
    "])\n",
    "train_dataset = datasets.MNIST(root='mnist_data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='mnist_data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DDPMScheduler\n",
    "\n",
    "noise_scheduler = DDPMScheduler(num_train_timesteps=150) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18750\n"
     ]
    }
   ],
   "source": [
    "from diffusers.optimization import get_cosine_schedule_with_warmup\n",
    "\n",
    "num_train_steps = len(train_loader) * 10\n",
    "print(num_train_steps)\n",
    "\n",
    "lr_scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=50,\n",
    "    num_training_steps=(num_train_steps),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/usr/local/lib/python3.10/dist-packages/diffusers/configuration_utils.py:140: FutureWarning: Accessing config attribute `num_train_timesteps` directly via 'DDPMScheduler' object attribute is deprecated. Please access 'num_train_timesteps' over 'DDPMScheduler's config object instead, e.g. 'scheduler.config.num_train_timesteps'.\n",
      "  deprecate(\"direct config name access\", \"1.0.0\", deprecation_message, standard_warn=False)\n",
      "1875it [04:51,  6.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 0.059813931584358215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [04:47,  6.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.047683872282505035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [04:52,  6.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 0.034084219485521317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [05:02,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 0.039008501917123795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57it [00:09,  6.02it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m timesteps \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, noise_scheduler\u001b[38;5;241m.\u001b[39mnum_train_timesteps, (bs,), device\u001b[38;5;241m=\u001b[39mclean_images\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m     11\u001b[0m noisy_images \u001b[38;5;241m=\u001b[39m noise_scheduler\u001b[38;5;241m.\u001b[39madd_noise(clean_images, noise, timesteps)\n\u001b[0;32m---> 13\u001b[0m noise_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoisy_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimesteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmse_loss(noise_pred, noise)\n\u001b[1;32m     15\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/diffusers/models/unets/unet_2d.py:329\u001b[0m, in \u001b[0;36mUNet2DModel.forward\u001b[0;34m(self, sample, timestep, class_labels, return_dict)\u001b[0m\n\u001b[1;32m    327\u001b[0m         sample, skip_sample \u001b[38;5;241m=\u001b[39m upsample_block(sample, res_samples, emb, skip_sample)\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 329\u001b[0m         sample \u001b[38;5;241m=\u001b[39m \u001b[43mupsample_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mres_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m# 6. post-process\u001b[39;00m\n\u001b[1;32m    332\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_norm_out(sample)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/diffusers/models/unets/unet_2d_blocks.py:2673\u001b[0m, in \u001b[0;36mUpBlock2D.forward\u001b[0;34m(self, hidden_states, res_hidden_states_tuple, temb, upsample_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2669\u001b[0m             hidden_states \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m   2670\u001b[0m                 create_custom_forward(resnet), hidden_states, temb\n\u001b[1;32m   2671\u001b[0m             )\n\u001b[1;32m   2672\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2673\u001b[0m         hidden_states \u001b[38;5;241m=\u001b[39m \u001b[43mresnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2675\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupsamplers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2676\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m upsampler \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupsamplers:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/diffusers/models/resnet.py:345\u001b[0m, in \u001b[0;36mResnetBlock2D.forward\u001b[0;34m(self, input_tensor, temb, *args, **kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_emb_proj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_time_act:\n\u001b[0;32m--> 345\u001b[0m         temb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnonlinearity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m     temb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_emb_proj(temb)[:, :, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_embedding_norm \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py:396\u001b[0m, in \u001b[0;36mSiLU.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msilu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2102\u001b[0m, in \u001b[0;36msilu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   2100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   2101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39msilu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m-> 2102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msilu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    for i, (clean_images, labels) in tqdm(enumerate(train_loader)):\n",
    "        noise = torch.randn(clean_images.shape)\n",
    "        bs = clean_images.shape[0]\n",
    "        labels = labels\n",
    "\n",
    "        timesteps = torch.randint(0, noise_scheduler.num_train_timesteps, (bs,), device=clean_images.device).long()\n",
    "        noisy_images = noise_scheduler.add_noise(clean_images, noise, timesteps)\n",
    "\n",
    "        noise_pred = model(noisy_images, timesteps, labels, return_dict=False)[0]\n",
    "        loss = F.mse_loss(noise_pred, noise)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    \n",
    "    print(f'Epoch {epoch} Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch._C.Generator"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(torch.manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model: UNet2DModel,\n",
    "              scheduler: DDPMScheduler,\n",
    "              batch_size: int,\n",
    "              generator: torch._C.Generator,\n",
    "              num_inference_steps: int,\n",
    "              label: int) -> np.ndarray:\n",
    "    \n",
    "    image_shape = (batch_size, 1, 28, 28)\n",
    "    labels = torch.full((batch_size,), label)\n",
    "\n",
    "    image = torch.randn(image_shape)\n",
    "\n",
    "    # set step values\n",
    "    scheduler.set_timesteps(num_inference_steps)\n",
    "\n",
    "    for t in scheduler.timesteps:\n",
    "        # 1. predict noise model_output\n",
    "        model_output = model(image, t, labels).sample\n",
    "\n",
    "        # 2. compute previous image: x_t -> x_t-1\n",
    "        image = scheduler.step(model_output, t, image, generator=generator).prev_sample\n",
    "\n",
    "    image = (image / 2 + 0.5).clamp(0, 1)\n",
    "    image = image.permute(0, 2, 3, 1)\n",
    "\n",
    "    return image.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = inference(model=model,\n",
    "                   scheduler=noise_scheduler,\n",
    "                   batch_size=10,\n",
    "                   generator=torch.manual_seed(42),\n",
    "                   num_inference_steps=150,\n",
    "                   label=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x800 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show images\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(2, 5, figsize=(20, 8))\n",
    "for i in range(10):\n",
    "    ax[i // 5, i % 5].imshow(images[i], cmap='gray')\n",
    "    ax[i // 5, i % 5].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
